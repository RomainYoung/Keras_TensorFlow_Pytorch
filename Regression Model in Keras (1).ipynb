{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "76fca115-8379-4851-9fed-936b68409118",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from tensorflow.keras.models import Sequential  # Use Sequential from TensorFlow Keras\n",
    "from tensorflow.keras.layers import Dense # Use Dense from TensorFlow Keras\n",
    "\n",
    "# Removed the standalone Keras imports to avoid confusion and errors\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "a3f60d56-a846-4ce1-ace6-168b042ec7be",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the data\n",
    "data_url = \"concrete_data.csv\"\n",
    "data = pd.read_csv(data_url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "ce8f19d2-5d44-4435-a2f3-6fba4308c48e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Split the data into predictors and target\n",
    "X = data.drop(columns=['Strength'])\n",
    "y = data['Strength']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45332e22-e9b4-4230-9ad5-c23373059525",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Initialize lists to store mean squared errors\n",
    "mse_list = []\n",
    "\n",
    "# Repeat the process 50 times\n",
    "for _ in range(50):\n",
    "    # Split the data into training and testing sets\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=None)\n",
    "\n",
    "    # Build the model\n",
    "    model = Sequential()\n",
    "    model.add(Dense(10, activation='relu', input_shape=(X_train.shape[1],)))\n",
    "    model.add(Dense(1))  # Output layer\n",
    "\n",
    "    # Compile the model\n",
    "    model.compile(optimizer='adam', loss='mean_squared_error')\n",
    "\n",
    "    # Train the model\n",
    "    model.fit(X_train, y_train, epochs=50, verbose=0)\n",
    "\n",
    "    # Evaluate the model\n",
    "    y_pred = model.predict(X_test)\n",
    "    mse = mean_squared_error(y_test, y_pred)\n",
    "    mse_list.append(mse)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "28319717-8042-4480-b67d-6444c6ff363a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean of Mean Squared Errors: 508.6600544733663\n",
      "Standard Deviation of Mean Squared Errors: 1013.9210584038176\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Calculate and report the mean and standard deviation of the mean squared errors\n",
    "mean_mse = np.mean(mse_list)\n",
    "std_mse = np.std(mse_list)\n",
    "\n",
    "print(f\"Mean of Mean Squared Errors: {mean_mse}\")\n",
    "print(f\"Standard Deviation of Mean Squared Errors: {std_mse}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "900fd855-97cc-4bb8-a6e1-8ff65dde9145",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import StandardScaler for normalization\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Normalize the data\n",
    "scaler = StandardScaler()\n",
    "X_normalized = scaler.fit_transform(X)\n",
    "\n",
    "# Initialize lists to store mean squared errors\n",
    "mse_list_normalized = []\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15bcbeaf-2019-4460-b0ca-5672af0439f5",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Repeat the process 50 times\n",
    "for _ in range(50):\n",
    "    # Split the normalized data into training and testing sets\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X_normalized, y, test_size=0.3, random_state=None)\n",
    "\n",
    "    # Build the model\n",
    "    model = Sequential()\n",
    "    model.add(Dense(10, activation='relu', input_shape=(X_train.shape[1],)))\n",
    "    model.add(Dense(1))  # Output layer\n",
    "\n",
    "    # Compile the model\n",
    "    model.compile(optimizer='adam', loss='mean_squared_error')\n",
    "\n",
    "    # Train the model\n",
    "    model.fit(X_train, y_train, epochs=50, verbose=0)\n",
    "\n",
    "    # Evaluate the model\n",
    "    y_pred = model.predict(X_test)\n",
    "    mse = mean_squared_error(y_test, y_pred)\n",
    "    mse_list_normalized.append(mse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "e5408269-e8ae-45ce-8339-208d235c6f37",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean of Mean Squared Errors (Normalized): 364.74622636273614\n",
      "Standard Deviation of Mean Squared Errors (Normalized): 88.35089769061719\n"
     ]
    }
   ],
   "source": [
    "# Calculate and report the mean and standard deviation of the mean squared errors\n",
    "mean_mse_normalized = np.mean(mse_list_normalized)\n",
    "std_mse_normalized = np.std(mse_list_normalized)\n",
    "\n",
    "print(f\"Mean of Mean Squared Errors (Normalized): {mean_mse_normalized}\")\n",
    "print(f\"Standard Deviation of Mean Squared Errors (Normalized): {std_mse_normalized}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03dfbf28-a706-4df1-a85c-01bc6124595b",
   "metadata": {},
   "source": [
    "**By normalizing the data, the mean MSE significantly decreases, indicating improved model performance. The standard deviation also decreases substantially, suggesting that the predictions are more consistent across different runs. Normalization helps in stabilizing the learning process by ensuring that all input features contribute equally.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9753be0-ee9d-43b3-abf3-716412355b02",
   "metadata": {},
   "outputs": [],
   "source": [
    "mse_list_100_epochs = []\n",
    "\n",
    "# Repeat the process 50 times\n",
    "for _ in range(50):\n",
    "    # Split the normalized data into training and testing sets\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X_normalized, y, test_size=0.3, random_state=None)\n",
    "\n",
    "    # Build the model\n",
    "    model = Sequential()\n",
    "    model.add(Dense(10, activation='relu', input_shape=(X_train.shape[1],)))\n",
    "    model.add(Dense(1))  # Output layer\n",
    "\n",
    "    # Compile the model\n",
    "    model.compile(optimizer='adam', loss='mean_squared_error')\n",
    "\n",
    "    # Train the model with 100 epochs\n",
    "    model.fit(X_train, y_train, epochs=100, verbose=0)\n",
    "\n",
    "    # Evaluate the model\n",
    "    y_pred = model.predict(X_test)\n",
    "    mse = mean_squared_error(y_test, y_pred)\n",
    "    mse_list_100_epochs.append(mse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "6997ee5f-65cc-47aa-b436-6a8236f2f808",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean of Mean Squared Errors (100 Epochs): 162.3707582427154\n",
      "Standard Deviation of Mean Squared Errors (100 Epochs): 19.219249953937876\n"
     ]
    }
   ],
   "source": [
    "# Calculate and report the mean and standard deviation of the mean squared errors\n",
    "mean_mse_100_epochs = np.mean(mse_list_100_epochs)\n",
    "std_mse_100_epochs = np.std(mse_list_100_epochs)\n",
    "\n",
    "print(f\"Mean of Mean Squared Errors (100 Epochs): {mean_mse_100_epochs}\")\n",
    "print(f\"Standard Deviation of Mean Squared Errors (100 Epochs): {std_mse_100_epochs}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c40b58b3-87e8-4d3c-ac78-30823e0e401d",
   "metadata": {},
   "source": [
    "**Increasing the number of epochs from 50 to 100 further reduces the mean MSE, indicating that the model benefits from additional training time, allowing it to learn more from the data. The standard deviation is also reduced, showing that the model's performance is more consistent. However, care must be taken to ensure that the model is not overfitting.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d810fcd2-d864-452d-9a20-82a1b1338447",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Initialize lists to store mean squared errors\n",
    "mse_list_multiple_layers = []\n",
    "\n",
    "# Repeat the process 50 times\n",
    "for _ in range(50):\n",
    "    # Split the normalized data into training and testing sets\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X_normalized, y, test_size=0.3, random_state=None)\n",
    "\n",
    "    # Build the model with three hidden layers\n",
    "    model = Sequential()\n",
    "    model.add(Dense(10, activation='relu', input_shape=(X_train.shape[1],)))\n",
    "    model.add(Dense(10, activation='relu'))\n",
    "    model.add(Dense(10, activation='relu'))\n",
    "    model.add(Dense(1))  # Output layer\n",
    "\n",
    "    # Compile the model\n",
    "    model.compile(optimizer='adam', loss='mean_squared_error')\n",
    "\n",
    "    # Train the model\n",
    "    model.fit(X_train, y_train, epochs=50, verbose=0)\n",
    "\n",
    "    # Evaluate the model\n",
    "    y_pred = model.predict(X_test)\n",
    "    mse = mean_squared_error(y_test, y_pred)\n",
    "    mse_list_multiple_layers.append(mse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "6aee1226-5e32-4e75-9866-37d7f1441407",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean of Mean Squared Errors (Multiple Layers): 130.62697980320482\n",
      "Standard Deviation of Mean Squared Errors (Multiple Layers): 15.3532900844214\n"
     ]
    }
   ],
   "source": [
    "# Calculate and report the mean and standard deviation of the mean squared errors\n",
    "mean_mse_multiple_layers = np.mean(mse_list_multiple_layers)\n",
    "std_mse_multiple_layers = np.std(mse_list_multiple_layers)\n",
    "\n",
    "print(f\"Mean of Mean Squared Errors (Multiple Layers): {mean_mse_multiple_layers}\")\n",
    "print(f\"Standard Deviation of Mean Squared Errors (Multiple Layers): {std_mse_multiple_layers}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7820c690-c032-4195-ac15-6cbaf6044f6c",
   "metadata": {},
   "source": [
    "**Adding more hidden layers results in the lowest mean MSE among all configurations, suggesting that the model can capture more complex patterns in the data. The reduced standard deviation indicates that this architecture provides consistent performance across different runs. The additional layers allow the model to learn hierarchical representations of the data, which can be beneficial for complex datasets.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac06bb3e-9f4c-47d6-bc25-51f22096863f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
